{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11602582,"sourceType":"datasetVersion","datasetId":7276918}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ================\n# 1. Libraries\n# ================\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:02:35.794553Z","iopub.execute_input":"2025-04-28T16:02:35.795759Z","iopub.status.idle":"2025-04-28T16:02:35.802161Z","shell.execute_reply.started":"2025-04-28T16:02:35.795726Z","shell.execute_reply":"2025-04-28T16:02:35.800891Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ================\n# 2. Load Dataset\n# ================\ntrain_df = pd.read_csv('/kaggle/input/features-ai-vs-human/train_features_updated_SNR.csv')\ntest_df = pd.read_csv('/kaggle/input/features-ai-vs-human/test_features_updated_SNR.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:03:05.899354Z","iopub.execute_input":"2025-04-28T16:03:05.899785Z","iopub.status.idle":"2025-04-28T16:03:06.662611Z","shell.execute_reply.started":"2025-04-28T16:03:05.899756Z","shell.execute_reply":"2025-04-28T16:03:06.661695Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ================\n# 3. Feature Engineering\n# ================\nimportant_features = [\n    'SNR', 'LaplacianVar', 'EdgeDensity',\n    'SatVariance', 'HueVariance', 'HighFreqEnergy'\n]\n\nfor df in [train_df, test_df]:\n    df['SatEdgeRatio'] = df['SatVariance'] / (df['EdgeDensity'] + 1e-5)\n    df['log_SNR'] = np.log(df['SNR'] + 1e-5)\n\nfeature_cols = important_features + ['SatEdgeRatio', 'log_SNR']\n\n# Select features - keep as pandas DataFrame\nX = train_df[feature_cols]\ny = train_df['label'].astype(int)\nX_test = test_df[feature_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:08:59.709390Z","iopub.execute_input":"2025-04-28T16:08:59.710349Z","iopub.status.idle":"2025-04-28T16:08:59.727129Z","shell.execute_reply.started":"2025-04-28T16:08:59.710322Z","shell.execute_reply":"2025-04-28T16:08:59.725511Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# ================\n# 4. Scaling\n# ================\nX = X.replace([np.inf, -np.inf], np.nan)\nX_test = X_test.replace([np.inf, -np.inf], np.nan)\n\n# Fill NaNs with column means\nX = X.fillna(X.mean())\nX_test = X_test.fillna(X.mean()) \n\nscaler = RobustScaler()\nX = scaler.fit_transform(X)\nX_test = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:09:02.078947Z","iopub.execute_input":"2025-04-28T16:09:02.079240Z","iopub.status.idle":"2025-04-28T16:09:02.168082Z","shell.execute_reply.started":"2025-04-28T16:09:02.079221Z","shell.execute_reply":"2025-04-28T16:09:02.167204Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# ================\n# 5. Train-Validation Split\n# ================\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:09:28.349032Z","iopub.execute_input":"2025-04-28T16:09:28.349352Z","iopub.status.idle":"2025-04-28T16:09:28.392538Z","shell.execute_reply.started":"2025-04-28T16:09:28.349331Z","shell.execute_reply":"2025-04-28T16:09:28.391509Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# ================\n# 6. Logistic Regression\n# ================\nlogreg_model = LogisticRegression(max_iter=1000)\nlogreg_model.fit(X_train, y_train)\nval_preds_logreg = logreg_model.predict_proba(X_val)[:, 1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:09:35.059032Z","iopub.execute_input":"2025-04-28T16:09:35.059323Z","iopub.status.idle":"2025-04-28T16:09:36.158091Z","shell.execute_reply.started":"2025-04-28T16:09:35.059305Z","shell.execute_reply":"2025-04-28T16:09:36.154977Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# ================\n# 7. XGBoost\n# ================\nxgb_model = xgb.XGBClassifier(\n    n_estimators=1000,\n    learning_rate=0.01,\n    max_depth=4,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42,\n    use_label_encoder=False,\n    eval_metric='auc'\n)\n\nxgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=50)\nval_preds_xgb = xgb_model.predict_proba(X_val)[:, 1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:09:53.379328Z","iopub.execute_input":"2025-04-28T16:09:53.379684Z","iopub.status.idle":"2025-04-28T16:10:01.755596Z","shell.execute_reply.started":"2025-04-28T16:09:53.379618Z","shell.execute_reply":"2025-04-28T16:10:01.754892Z"}},"outputs":[{"name":"stdout","text":"[0]\tvalidation_0-auc:0.72114\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[50]\tvalidation_0-auc:0.73424\n[100]\tvalidation_0-auc:0.73746\n[150]\tvalidation_0-auc:0.74057\n[200]\tvalidation_0-auc:0.74344\n[250]\tvalidation_0-auc:0.74619\n[300]\tvalidation_0-auc:0.74897\n[350]\tvalidation_0-auc:0.75087\n[400]\tvalidation_0-auc:0.75281\n[450]\tvalidation_0-auc:0.75444\n[500]\tvalidation_0-auc:0.75556\n[550]\tvalidation_0-auc:0.75653\n[600]\tvalidation_0-auc:0.75730\n[650]\tvalidation_0-auc:0.75798\n[700]\tvalidation_0-auc:0.75850\n[750]\tvalidation_0-auc:0.75896\n[800]\tvalidation_0-auc:0.75935\n[850]\tvalidation_0-auc:0.75974\n[900]\tvalidation_0-auc:0.76016\n[950]\tvalidation_0-auc:0.76041\n[999]\tvalidation_0-auc:0.76062\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# ================\n# 8. Neural Network\n# ================\nnn_model = Sequential([\n    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n    Dropout(0.2),\n    Dense(16, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\nnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nnn_model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_val, y_val), verbose=2)\nval_preds_nn = nn_model.predict(X_val).flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:10:17.349489Z","iopub.execute_input":"2025-04-28T16:10:17.350368Z","iopub.status.idle":"2025-04-28T16:11:30.466853Z","shell.execute_reply.started":"2025-04-28T16:10:17.350341Z","shell.execute_reply":"2025-04-28T16:11:30.465729Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"1000/1000 - 4s - 4ms/step - accuracy: 0.6717 - loss: 0.6511 - val_accuracy: 0.6782 - val_loss: 0.6090\nEpoch 2/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6803 - loss: 0.6204 - val_accuracy: 0.6837 - val_loss: 0.6008\nEpoch 3/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6813 - loss: 0.6107 - val_accuracy: 0.6855 - val_loss: 0.6181\nEpoch 4/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6839 - loss: 0.6141 - val_accuracy: 0.6886 - val_loss: 0.5935\nEpoch 5/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6856 - loss: 0.6244 - val_accuracy: 0.6906 - val_loss: 0.5988\nEpoch 6/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6886 - loss: 0.6029 - val_accuracy: 0.6891 - val_loss: 0.6333\nEpoch 7/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6876 - loss: 0.6310 - val_accuracy: 0.6919 - val_loss: 0.6639\nEpoch 8/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6884 - loss: 0.6020 - val_accuracy: 0.6942 - val_loss: 0.5876\nEpoch 9/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6877 - loss: 0.6094 - val_accuracy: 0.6944 - val_loss: 0.5899\nEpoch 10/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6909 - loss: 0.5900 - val_accuracy: 0.6946 - val_loss: 0.5841\nEpoch 11/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6919 - loss: 0.5954 - val_accuracy: 0.6961 - val_loss: 0.5930\nEpoch 12/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6912 - loss: 0.5894 - val_accuracy: 0.6979 - val_loss: 0.5872\nEpoch 13/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6930 - loss: 0.5902 - val_accuracy: 0.6994 - val_loss: 0.5883\nEpoch 14/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6932 - loss: 0.5922 - val_accuracy: 0.6977 - val_loss: 0.5788\nEpoch 15/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6927 - loss: 0.6067 - val_accuracy: 0.6970 - val_loss: 0.5858\nEpoch 16/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6932 - loss: 0.5974 - val_accuracy: 0.6986 - val_loss: 0.5805\nEpoch 17/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6938 - loss: 0.5815 - val_accuracy: 0.6991 - val_loss: 0.5784\nEpoch 18/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6940 - loss: 0.5866 - val_accuracy: 0.7013 - val_loss: 0.5815\nEpoch 19/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6942 - loss: 0.5861 - val_accuracy: 0.6978 - val_loss: 0.5808\nEpoch 20/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6941 - loss: 0.5855 - val_accuracy: 0.7006 - val_loss: 0.5792\nEpoch 21/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6947 - loss: 0.5862 - val_accuracy: 0.6991 - val_loss: 0.5838\nEpoch 22/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6945 - loss: 0.5814 - val_accuracy: 0.7003 - val_loss: 0.5780\nEpoch 23/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6968 - loss: 0.5834 - val_accuracy: 0.6993 - val_loss: 0.5810\nEpoch 24/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6953 - loss: 0.5833 - val_accuracy: 0.6997 - val_loss: 0.5805\nEpoch 25/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6949 - loss: 0.5832 - val_accuracy: 0.7008 - val_loss: 0.5839\nEpoch 26/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6940 - loss: 0.5823 - val_accuracy: 0.7004 - val_loss: 0.5777\nEpoch 27/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6967 - loss: 0.5818 - val_accuracy: 0.7023 - val_loss: 0.5765\nEpoch 28/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6971 - loss: 0.5788 - val_accuracy: 0.7024 - val_loss: 0.5765\nEpoch 29/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6952 - loss: 0.5834 - val_accuracy: 0.7026 - val_loss: 0.5791\nEpoch 30/30\n1000/1000 - 2s - 2ms/step - accuracy: 0.6960 - loss: 0.5796 - val_accuracy: 0.7008 - val_loss: 0.5764\n\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# ================\n# 9. Optimize Blend Weights\n# ================\nblend_weights = np.linspace(0, 1, 101)\nbest_f1 = 0\nbest_w1, best_w2, best_w3 = 0, 0, 0\n\nfor w1 in blend_weights:\n    for w2 in blend_weights:\n        if w1 + w2 > 1:\n            continue\n        w3 = 1 - w1 - w2\n        blended_preds = (w1 * val_preds_logreg) + (w2 * val_preds_xgb) + (w3 * val_preds_nn)\n        score = f1_score(y_val, (blended_preds > 0.5).astype(int))\n        if score > best_f1:\n            best_f1 = score\n            best_w1, best_w2, best_w3 = w1, w2, w3\n\nprint(f\"âœ… Best Blend Weights: Logistic {best_w1:.2f}, XGB {best_w2:.2f}, NN {best_w3:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:11:36.064971Z","iopub.execute_input":"2025-04-28T16:11:36.065328Z","iopub.status.idle":"2025-04-28T16:12:13.374115Z","shell.execute_reply.started":"2025-04-28T16:11:36.065307Z","shell.execute_reply":"2025-04-28T16:12:13.373026Z"}},"outputs":[{"name":"stdout","text":"âœ… Best Blend Weights: Logistic 0.09, XGB 0.07, NN 0.84\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# ================\n# 10. Optimize Final Threshold\n# ================\nfinal_blended_val_preds = (best_w1 * val_preds_logreg) + (best_w2 * val_preds_xgb) + (best_w3 * val_preds_nn)\n\nbest_thresh = 0.5\nbest_thresh_score = 0\n\nfor thresh in np.linspace(0.3, 0.7, 101):\n    preds_binary = (final_blended_val_preds > thresh).astype(int)\n    score = f1_score(y_val, preds_binary)\n    if score > best_thresh_score:\n        best_thresh_score = score\n        best_thresh = thresh\n\nprint(f\"âœ… Best Final Threshold: {best_thresh:.4f} with F1: {best_thresh_score:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:12:29.081373Z","iopub.execute_input":"2025-04-28T16:12:29.081923Z","iopub.status.idle":"2025-04-28T16:12:29.804212Z","shell.execute_reply.started":"2025-04-28T16:12:29.081886Z","shell.execute_reply":"2025-04-28T16:12:29.802871Z"}},"outputs":[{"name":"stdout","text":"âœ… Best Final Threshold: 0.3600 with F1: 0.72322\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# ================\n# 11. Predict on Test Set\n# ================\ntest_preds_logreg = logreg_model.predict_proba(X_test)[:, 1]\ntest_preds_xgb = xgb_model.predict_proba(X_test)[:, 1]\ntest_preds_nn = nn_model.predict(X_test).flatten()\n\nblended_test_preds = (best_w1 * test_preds_logreg) + (best_w2 * test_preds_xgb) + (best_w3 * test_preds_nn)\n\nfinal_test_labels = (blended_test_preds > best_thresh).astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:12:40.685442Z","iopub.execute_input":"2025-04-28T16:12:40.685798Z","iopub.status.idle":"2025-04-28T16:12:41.146921Z","shell.execute_reply.started":"2025-04-28T16:12:40.685775Z","shell.execute_reply":"2025-04-28T16:12:41.145608Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m174/174\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# ================\n# 12. Create Final Submission\n# ================\nsubmission = pd.DataFrame({\n    'id': test_df['id'],\n    'label': final_test_labels\n})\n\nsubmission['id'] = submission['id'].apply(lambda x: f'test_data_v2/{x}')\nsubmission.to_csv('/kaggle/working/final_submission_XG_NN_LG.csv', index=False)\n\nprint(\"ğŸ¯ Final Submission File Created Successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T16:13:09.228536Z","iopub.execute_input":"2025-04-28T16:13:09.229059Z","iopub.status.idle":"2025-04-28T16:13:09.255559Z","shell.execute_reply.started":"2025-04-28T16:13:09.229018Z","shell.execute_reply":"2025-04-28T16:13:09.254393Z"}},"outputs":[{"name":"stdout","text":"ğŸ¯ Final Submission File Created Successfully!\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}